{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PytorchGPU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ljdn33KX66UZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "from torch.autograd import Variable "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nSHTijKXt9xI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### pytorch GPU and its operation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dGyLkZVo7X3M",
        "colab_type": "code",
        "outputId": "cf8a9c08-fd30-483e-c54f-5025749eccfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# checking the GPU and its name\n",
        "if torch.cuda.is_available():\n",
        "  print('cuda is supported')\n",
        "else:\n",
        "  print('GPU is not supported')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda is supported\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-fLoVbio9GE4",
        "colab_type": "code",
        "outputId": "20b7e0c6-c60d-4149-c6a2-fd6beb91ed9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# check the no of GPU attached in the CPU\n",
        "torch.cuda.device_count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "ihYRwrTR9Vl7",
        "colab_type": "code",
        "outputId": "2f0cf3c6-3dee-4caf-950b-abd74fc16058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Find Device Name\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla K80'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "47o-60pR-eqn",
        "colab_type": "code",
        "outputId": "f3c8a89f-7a2c-46d1-b010-42807b758ce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# making a tensor to GPU\n",
        "tf=torch.FloatTensor([11.34])\n",
        "tf=tf.cuda(0)\n",
        "print(tf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([11.3400], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i3rcUNMc-x_7",
        "colab_type": "code",
        "outputId": "2551d339-b154-41d8-ea36-0274e88dc12b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# create a tensor in cuda directly\n",
        "t2=torch.cuda.FloatTensor([2.3])\n",
        "print(t2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2.3000], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gnOa9Al7_dcN",
        "colab_type": "code",
        "outputId": "66c0220e-c60a-4e58-ffd9-8c26c58b679b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# bring the Tensor to cpu\n",
        "t2=t2.cpu()\n",
        "print(t2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2.3000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yjSr_Jk0_tUj",
        "colab_type": "code",
        "outputId": "f3d0540f-6a86-4bf4-baa5-c7d7d677630f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Use Device context, we can write a block of variable and operation within it\n",
        "with torch.cuda.device(0):\n",
        "  t5=torch.cuda.IntTensor([2,3,4])\n",
        "  t6=torch.cuda.IntTensor([5,6,7])\n",
        "  result=t5+t6\n",
        "  print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 7,  9, 11], device='cuda:0', dtype=torch.int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pL87rtr1BUST",
        "colab_type": "code",
        "outputId": "35b3565d-fb9e-441d-8a25-27f99d814375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# here we are creating a cuda GPU block but still we are not adding variable in GPU so it is not created in GPU\n",
        "with torch.cuda.device(0):\n",
        "  a=torch.Tensor([1,2,3])\n",
        "  b=torch.Tensor([4,5,6])\n",
        "  c=a+b\n",
        "  print(c)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5., 7., 9.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qAf-lGnODKNf",
        "colab_type": "code",
        "outputId": "05a72f94-91e3-4bad-a623-63b7b69c88c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# asign GPU tensor in variable\n",
        "v3=Variable(torch.cuda.FloatTensor([123]))\n",
        "print(v3)\n",
        "\n",
        "vb1=torch.cuda.FloatTensor([11.90])\n",
        "vb2=Variable(vb1, requires_grad=True)\n",
        "print(vb2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([123.], device='cuda:0')\n",
            "tensor([11.9000], device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OpTHSaJSEbNg",
        "colab_type": "code",
        "outputId": "919e4bbd-223b-4359-83ab-875e7d9a055e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-13d700ddecd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Variable data has to be a tensor, but got list"
          ]
        }
      ]
    }
  ]
}